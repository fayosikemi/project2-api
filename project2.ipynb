{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Web Scraping and API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/is310/lib/python3.9/site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the html for Wikipedia articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Using inspect element, copy the html code for a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<th class =\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Year</th>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: ['headerSort']\n",
      "Tabindex: 0\n",
      "Role: columnheader button\n",
      "Title: Sort ascending\n",
      "Header Text: Year\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML\n",
    "html_snippet = \"\"\"\n",
    "<th class=\"headerSort\" tabindex=\"0\" role=\"columnheader button\" title=\"Sort ascending\">Year</th>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_snippet, 'html.parser')\n",
    "\n",
    "th_element = soup.find('th')\n",
    "\n",
    "class_name = th_element.get('class')\n",
    "tab_index = th_element.get('tabindex')\n",
    "role = th_element.get('role')\n",
    "title = th_element.get('title')\n",
    "header_text = th_element.get_text()\n",
    "\n",
    "print(\"Class:\", class_name)\n",
    "print(\"Tabindex:\", tab_index)\n",
    "print(\"Role:\", role)\n",
    "print(\"Title:\", title)\n",
    "print(\"Header Text:\", header_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Using inspect element, find the html syntax for a link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link URL: https://en.wikipedia.org/wiki/American_Library_Association\n",
      "Title: American Library Association\n",
      "Link Text: American Library Association\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML with an anchor element\n",
    "html_snippet = \"\"\"\n",
    "<a href=\"https://en.wikipedia.org/wiki/American_Library_Association\" title=\"American Library Association\">American Library Association</a>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_snippet, 'html.parser')\n",
    "\n",
    "a_element = soup.find('a')\n",
    "\n",
    "href = a_element.get('href')\n",
    "title = a_element.get('title')\n",
    "link_text = a_element.get_text()\n",
    "\n",
    "print(\"Link URL:\", href)\n",
    "print(\"Title:\", title)\n",
    "print(\"Link Text:\", link_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Using inspect element, find the html syntax for linking an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link URL: https://en.wikipedia.org/wiki/Young_Adult_Library_Services_Association\n",
      "Image URL: https://upload.wikimedia.org/wikipedia/commons/8/89/Example.jpg\n",
      "Alt Text: Example Image\n",
      "Image Width: 200\n",
      "Image Height: 150\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML for a linked image\n",
    "html_snippet = \"\"\"\n",
    "<a href=\"https://en.wikipedia.org/wiki/Young_Adult_Library_Services_Association\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/8/89/Example.jpg\" alt=\"Example Image\" width=\"200\" height=\"150\">\n",
    "</a>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_snippet, 'html.parser')\n",
    "\n",
    "\n",
    "a_element = soup.find('a')\n",
    "\n",
    "\n",
    "link_url = a_element.get('href')\n",
    "\n",
    "\n",
    "img_element = a_element.find('img')\n",
    "\n",
    "img_src = img_element.get('src')\n",
    "img_alt = img_element.get('alt')\n",
    "img_width = img_element.get('width')\n",
    "img_height = img_element.get('height')\n",
    "\n",
    "print(\"Link URL:\", link_url)\n",
    "print(\"Image URL:\", img_src)\n",
    "print(\"Alt Text:\", img_alt)\n",
    "print(\"Image Width:\", img_width)\n",
    "print(\"Image Height:\", img_height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Explore one Wikipedia page with the beautifulsoup package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully!\n",
      "Young Adult Library Services Association - Wikipedia\n",
      "Jump to content\n",
      "Main menu\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "Navigation\n",
      "Main page\n",
      "Contents\n",
      "Current events\n",
      "Random article\n",
      "About Wikipedia\n",
      "Contact us\n",
      "Contribute\n",
      "Help\n",
      "Learn to edit\n",
      "Community portal\n",
      "Recent changes\n",
      "Upload file\n",
      "Search\n",
      "Search\n",
      "Donate\n",
      "Appearance\n",
      "Create account\n",
      "Log in\n",
      "Personal tools\n",
      "Create account\n",
      "Log in\n",
      "Pages for logged out editors\n",
      "learn more\n",
      "Contributions\n",
      "Talk\n",
      "Contents\n",
      "move to sidebar\n",
      "hide\n",
      "(Top)\n",
      "1\n",
      "History\n",
      "2\n",
      "Awards\n",
      "3\n",
      "See also\n",
      "4\n",
      "References\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save and print the text content of a page with all tags removed\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Young_Adult_Library_Services_Association\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    page_content = response.content\n",
    "    print(\"Page fetched successfully!\")\n",
    "\n",
    "    soup = bs4.BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    text_content = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    with open(\"wiki_page_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_content)\n",
    "\n",
    "    print(text_content[:500])\n",
    "else:\n",
    "    print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully!\n",
      "Image downloaded and saved as downloaded_image.jpg\n"
     ]
    }
   ],
   "source": [
    "# download an image with beautifulsoup and save it in this repository\n",
    "\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Young_Adult_Library_Services_Association\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    page_content = response.content\n",
    "    print(\"Page fetched successfully!\")\n",
    "\n",
    "\n",
    "    soup = bs4.BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "    img_tag = soup.find('img')\n",
    "\n",
    "    if img_tag:\n",
    "    \n",
    "        img_src = img_tag['src']\n",
    "        \n",
    "        if img_src.startswith(\"//\"):\n",
    "            img_url = \"https:\" + img_src \n",
    "        elif img_src.startswith(\"/\"):\n",
    "            img_url = \"https://en.wikipedia.org\" + img_src \n",
    "        else:\n",
    "            img_url = img_src \n",
    "   \n",
    "        img_response = requests.get(img_url)\n",
    "\n",
    "        if img_response.status_code == 200:\n",
    "          \n",
    "            img_filename = os.path.join(\"downloaded_image.jpg\")\n",
    "            with open(img_filename, 'wb') as file:\n",
    "                file.write(img_response.content)\n",
    "            print(f\"Image downloaded and saved as {img_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve image. Status code: {img_response.status_code}\")\n",
    "    else:\n",
    "        print(\"No image found on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#bodyContent\n",
      "/wiki/Main_Page\n",
      "/wiki/Wikipedia:Contents\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Special:Random\n",
      "/wiki/Wikipedia:About\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "/wiki/Help:Contents\n",
      "/wiki/Help:Introduction\n",
      "/wiki/Wikipedia:Community_portal\n"
     ]
    }
   ],
   "source": [
    "#find all the links in a page with beautifulsoup\n",
    "#print the first 100 characters of ten of these links\n",
    "def find_links(url):\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    if page.status_code == 200: \n",
    "        soup = bs4.BeautifulSoup(page.content, 'html.parser')\n",
    "        links = soup.find_all('a')\n",
    "\n",
    "        for i in range(min(10, len(links))): \n",
    "            if 'href' in links[i].attrs: \n",
    "                print(links[i]['href'][:100]) \n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {page.status_code}\")\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Young_Adult_Library_Services_Association\"\n",
    "find_links(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Downloading scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts=pd.read_csv('pudding_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>script_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>gross (inflation-adjusted)</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0019777</td>\n",
       "      <td>4031</td>\n",
       "      <td>The Cocoanuts</td>\n",
       "      <td>1929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.pages.drexel.edu/~ina22/splaylib/Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0021884</td>\n",
       "      <td>8521</td>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>1931</td>\n",
       "      <td>298.0</td>\n",
       "      <td>Frankenstein (Florey &amp; Fort) [1931-5-23] [Scan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0022054</td>\n",
       "      <td>1086</td>\n",
       "      <td>The Last Flight</td>\n",
       "      <td>1931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>film_20100519/all_imsdb_05_19_10/Last-Flight,-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0022626</td>\n",
       "      <td>1631</td>\n",
       "      <td>American Madness</td>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.imsdb.com/Movie Scripts/American Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0022958</td>\n",
       "      <td>2438</td>\n",
       "      <td>Grand Hotel</td>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.imsdb.com/Movie Scripts/Grand Hotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>tt3733778</td>\n",
       "      <td>8533</td>\n",
       "      <td>Pay the Ghost</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pay The Ghost (Dan Kay, 9-1-09).pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>tt3808342</td>\n",
       "      <td>5499</td>\n",
       "      <td>Son of Saul</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://gointothestory.blcklst.com/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>tt3850214</td>\n",
       "      <td>8056</td>\n",
       "      <td>Dope</td>\n",
       "      <td>2015</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Dope (2013.10.31) [Digital].pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>tt3859076</td>\n",
       "      <td>5507</td>\n",
       "      <td>Truth</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>http://gointothestory.blcklst.com/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>tt4270516</td>\n",
       "      <td>5410</td>\n",
       "      <td>Grandma</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.0</td>\n",
       "      <td>http://gointothestory.blcklst.com/wp-content/u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        imdb_id  script_id             title  year  \\\n",
       "0     tt0019777       4031     The Cocoanuts  1929   \n",
       "1     tt0021884       8521      Frankenstein  1931   \n",
       "2     tt0022054       1086   The Last Flight  1931   \n",
       "3     tt0022626       1631  American Madness  1932   \n",
       "4     tt0022958       2438       Grand Hotel  1932   \n",
       "...         ...        ...               ...   ...   \n",
       "1995  tt3733778       8533     Pay the Ghost  2015   \n",
       "1996  tt3808342       5499       Son of Saul  2015   \n",
       "1997  tt3850214       8056              Dope  2015   \n",
       "1998  tt3859076       5507             Truth  2015   \n",
       "1999  tt4270516       5410           Grandma  2015   \n",
       "\n",
       "      gross (inflation-adjusted)  \\\n",
       "0                            NaN   \n",
       "1                          298.0   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "1995                         NaN   \n",
       "1996                         0.0   \n",
       "1997                        18.0   \n",
       "1998                         2.0   \n",
       "1999                         7.0   \n",
       "\n",
       "                                                   link  \n",
       "0     http://www.pages.drexel.edu/~ina22/splaylib/Sc...  \n",
       "1     Frankenstein (Florey & Fort) [1931-5-23] [Scan...  \n",
       "2     film_20100519/all_imsdb_05_19_10/Last-Flight,-...  \n",
       "3     http://www.imsdb.com/Movie Scripts/American Ma...  \n",
       "4     http://www.imsdb.com/Movie Scripts/Grand Hotel...  \n",
       "...                                                 ...  \n",
       "1995                Pay The Ghost (Dan Kay, 9-1-09).pdf  \n",
       "1996  http://gointothestory.blcklst.com/wp-content/u...  \n",
       "1997                    Dope (2013.10.31) [Digital].pdf  \n",
       "1998  http://gointothestory.blcklst.com/wp-content/u...  \n",
       "1999  http://gointothestory.blcklst.com/wp-content/u...  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing http://www.example.com/script_for_cocoanuts: 500 Server Error: Internal Server Error for url: http://www.example.com/script_for_cocoanuts\n",
      "Downloaded script_1.txt successfully.\n",
      "Downloaded script_2.txt successfully.\n",
      "Downloaded script_3.txt successfully.\n",
      "Downloaded script_4.txt successfully.\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Pay-the-Ghost.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Pay-the-Ghost.pdf?gi=095c6dbddf46\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Son-of-Saul.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Son-of-Saul.pdf?gi=0b572ae37527\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Dope.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Dope.pdf?gi=c9ebbd785dce\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Truth.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Truth.pdf?gi=dfdba2a8c4a3\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Grandma.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Grandma.pdf?gi=c16a4d7675d0\n"
     ]
    }
   ],
   "source": [
    "#using the links in the \"link\" column, download the first 1000 characters of each script\n",
    "#use requests and bs4, remember to remove all html tags\n",
    "\n",
    "data = {\n",
    " \"title\": [\"The Cocoanuts\", \"Frankenstein\", \"The Last Flight\", \"American Madness\", \"Grand Hotel\", \n",
    "              \"Pay the Ghost\", \"Son of Saul\", \"Dope\", \"Truth\", \"Grandma\"],\n",
    "    \"year\": [1929, 1931, 1931, 1932, 1932, 2015, 2015, 2015, 2015, 2015],\n",
    "    \"gross (inflation-adjusted)\": [None, 298.0, None, None, None, None, 0.0, 18.0, 2.0, 7.0],\n",
    "    \"link\": [\n",
    "        \"http://www.example.com/script_for_cocoanuts\",\n",
    "        \"https://www.imsdb.com/scripts/Frankenstein.html\",\n",
    "        \"https://www.imsdb.com/scripts/The-Last-Flight.html\",\n",
    "        \"https://www.imsdb.com/scripts/American-Madness.html\",\n",
    "        \"https://www.imsdb.com/scripts/Grand-Hotel.html\",\n",
    "        \"http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Pay-the-Ghost.pdf\",\n",
    "        \"http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Son-of-Saul.pdf\",\n",
    "        \"http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Dope.pdf\", \n",
    "        \"http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Truth.pdf\", \n",
    "        \"http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Grandma.pdf\"\n",
    "    ]\n",
    "}\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def download_scripts(data):\n",
    "    for i in range(len(data)):\n",
    "        url = data['link'][i]\n",
    "        \n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            page.raise_for_status() \n",
    "            \n",
    "            soup = bs4.BeautifulSoup(page.content, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "            \n",
    "            with open(f'script_{i}.txt', 'w', encoding='utf-8') as file:\n",
    "                file.write(text[:1000])\n",
    "                \n",
    "            print(f\"Downloaded script_{i}.txt successfully.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {url}: {e}\")\n",
    "\n",
    "download_scripts(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing http://www.example.com/script_for_cocoanuts: 500 Server Error: Internal Server Error for url: http://www.example.com/script_for_cocoanuts\n",
      "Downloaded script for Frankenstein successfully.\n",
      "Downloaded script for The Last Flight successfully.\n",
      "Downloaded script for American Madness successfully.\n",
      "Downloaded script for Grand Hotel successfully.\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Pay-the-Ghost.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Pay-the-Ghost.pdf?gi=b35c2a9ac9e2\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Son-of-Saul.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Son-of-Saul.pdf?gi=48b3d08b5c35\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Dope.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Dope.pdf?gi=6489a3c0fe78\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Truth.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Truth.pdf?gi=954cb5cf2055\n",
      "An error occurred while processing http://gointothestory.blcklst.com/wp-content/uploads/2015/09/Grandma.pdf: 404 Client Error: Not Found for url: https://gointothestory.blcklst.com/wp-content/uploads/2015/09/Grandma.pdf?gi=c9217b94cf8e\n",
      "DataFrame saved as 'pudding_texts.csv'.\n"
     ]
    }
   ],
   "source": [
    "#add a new column to the df with the text downloaded\n",
    "#save this new dataframe as \"pudding_texts.csv\"\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['script_text'] = \"\"\n",
    "\n",
    "def download_scripts(data):\n",
    "    for i in range(len(data)):\n",
    "        url = data['link'][i]\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            page.raise_for_status() \n",
    "            soup = bs4.BeautifulSoup(page.content, 'html.parser')\n",
    "            text = soup.get_text()\n",
    "            df.at[i, 'script_text'] = text[:1000]\n",
    "            print(f\"Downloaded script for {data['title'][i]} successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {url}: {e}\")\n",
    "\n",
    "download_scripts(df)\n",
    "\n",
    "df.to_csv(\"pudding_texts.csv\", index=False)\n",
    "print(\"DataFrame saved as 'pudding_texts.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: TMDB database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse the documentation at https://developer.themoviedb.org/reference/intro/getting-started. Create an account to authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"dates\":{\"maximum\":\"2024-10-09\",\"minimum\":\"2024-08-28\"},\"page\":1,\"results\":[{\"adult\":false,\"backdrop_path\":\"/9R9Za5kybgl5AhuCNoK3gngaBdG.jpg\",\"genre_ids\":[27,53],\"id\":1114513,\"original_language\":\"en\",\"original_title\":\"Speak No Evil\",\"overview\":\"When an American family is invited to spend the weekend at the idyllic country estate of a charming British family they befriended on vacation, what begins as a dream holiday soon warps into a snarled psychological nightmare.\",\"popularity\":2281.291,\"poster_path\":\"/fDtkrO2OAF8LKQTdzYmu1Y7lCLB.jpg\",\"release_date\":\"2024-09-11\",\"title\":\"Speak No Evil\",\"video\":false,\"vote_average\":7.334,\"vote_count\":511},{\"adult\":false,\"backdrop_path\":\"/uXDwP5qPhuRyPpQ7WkLbE6t2z5W.jpg\",\"genre_ids\":[35,53,28],\"id\":877817,\"original_language\":\"en\",\"original_title\":\"Wolfs\",\"overview\":\"Hired to cover up a high-profile crime, a fixer soon finds his night spiralling out of control when he's forced to work with an unexpected counterpart.\",\"popularity\":1693.793,\"poster_path\":\"/vOX1Zng472PC2KnS0B9nRfM8aaZ.jpg\",\"release_date\":\"2024-09-20\",\"title\":\"Wolfs\",\"video\":false,\"vote_average\":6.594,\"vote_count\":382},{\"adult\":false,\"backdrop_path\":\"/Asg2UUwipAdE87MxtJy7SQo08XI.jpg\",\"genre_ids\":[28,14,27,53,80],\"id\":957452,\"original_language\":\"en\",\"original_title\":\"The Crow\",\"overview\":\"Soulmates Eric and Shelly are brutally murdered when the demons of her dark past catch up with them. Given the chance to save his true love by sacrificing himself, Eric sets out to seek merciless revenge on their killers, traversing the worlds of the living and the dead to put the wrong things right.\",\"popularity\":1690.146,\"poster_path\":\"/58QT4cPJ2u2TqWZkterDq9q4yxQ.jpg\",\"release_date\":\"2024-08-21\",\"title\":\"The Crow\",\"video\":false,\"vote_average\":5.441,\"vote_count\":487},{\"adult\":false,\"backdrop_path\":\"/7h6TqPB3ESmjuVbxCxAeB1c9OB1.jpg\",\"genre_ids\":[878,27,35],\"id\":933260,\"original_language\":\"en\",\"original_title\":\"The Substance\",\"overview\":\"A fading celebrity decides to use a black market drug, a cell-replicating substance that temporarily creates a younger, better version of herself.\",\"popularity\":1595.704,\"poster_path\":\"/lqoMzCcZYEFK729d6qzt349fB4o.jpg\",\"release_date\":\"2024-09-07\",\"title\":\"The Substance\",\"video\":false,\"vote_average\":7.3,\"vote_count\":236},{\"adult\":false,\"backdrop_path\":\"/jFWuufqtmNlf0JdIQCndycH6eCr.jpg\",\"genre_ids\":[18,80,53],\"id\":889737,\"original_language\":\"en\",\"original_title\":\"Joker: Folie à Deux\",\"overview\":\"While struggling with his dual identity, Arthur Fleck not only stumbles upon true love, but also finds the music that's always been inside him.\",\"popularity\":1372.519,\"poster_path\":\"/if8QiqCI7WAGImKcJCfzp6VTyKA.jpg\",\"release_date\":\"2024-10-01\",\"title\":\"Joker: Folie à Deux\",\"video\":false,\"vote_average\":5.815,\"vote_count\":454},{\"adult\":false,\"backdrop_path\":\"/gHpTqPqSIC0jZ4J4QyXlVJ0yBcW.jpg\",\"genre_ids\":[28,80,53],\"id\":1215162,\"original_language\":\"en\",\"original_title\":\"Kill 'em All 2\",\"overview\":\"Phillip and Suzanne are retired from the spy game, living peacefully off the grid. That's until their whereabouts are discovered by Vlad, the vengeful brother of their target from the first film.\",\"popularity\":1369.344,\"poster_path\":\"/hgA5hN3NjNNSTXYOmAI6KNKOzbp.jpg\",\"release_date\":\"2024-09-24\",\"title\":\"Kill 'em All 2\",\"video\":false,\"vote_average\":6.986,\"vote_count\":70},{\"adult\":false,\"backdrop_path\":\"/hPIWQT70wQK6akqfLXByEvr62u0.jpg\",\"genre_ids\":[28,53,27,878],\"id\":726139,\"original_language\":\"ko\",\"original_title\":\"탈출: 프로젝트 사일런스\",\"overview\":\"Due to sudden deteriorating weather conditions, visibility on the Airport Bridge is severely impaired, leaving people stranded and at risk of the bridge collapsing due to a series of chain collisions and explosions. Amidst the chaos, the canine subjects \\\"Echo\\\" from the military experiment \\\"Project Silence,\\\" who were being transported in secret, break free, and all human survivors become targets of relentless attacks.\",\"popularity\":1331.711,\"poster_path\":\"/fttoFfKikQMwIoV3UVvlCvBhbUw.jpg\",\"release_date\":\"2024-07-11\",\"title\":\"Project Silence\",\"video\":false,\"vote_average\":6.808,\"vote_count\":112},{\"adult\":false,\"backdrop_path\":\"/4zlOPT9CrtIX05bBIkYxNZsm5zN.jpg\",\"genre_ids\":[16,878,10751],\"id\":1184918,\"original_language\":\"en\",\"original_title\":\"The Wild Robot\",\"overview\":\"After a shipwreck, an intelligent robot called Roz is stranded on an uninhabited island. To survive the harsh environment, Roz bonds with the island's animals and cares for an orphaned baby goose.\",\"popularity\":1328.503,\"poster_path\":\"/wTnV3PCVW5O92JMrFvvrRcV39RU.jpg\",\"release_date\":\"2024-09-12\",\"title\":\"The Wild Robot\",\"video\":false,\"vote_average\":7.961,\"vote_count\":114},{\"adult\":false,\"backdrop_path\":\"/A1dZ6faTjg0e6HYftBmEKujuXGQ.jpg\",\"genre_ids\":[35,14,27],\"id\":917496,\"original_language\":\"en\",\"original_title\":\"Beetlejuice Beetlejuice\",\"overview\":\"After a family tragedy, three generations of the Deetz family return home to Winter River. Still haunted by Betelgeuse, Lydia's life is turned upside down when her teenage daughter, Astrid, accidentally opens the portal to the Afterlife.\",\"popularity\":1105.772,\"poster_path\":\"/kKgQzkUCnQmeTPkyIwHly2t6ZFI.jpg\",\"release_date\":\"2024-09-04\",\"title\":\"Beetlejuice Beetlejuice\",\"video\":false,\"vote_average\":7.083,\"vote_count\":813},{\"adult\":false,\"backdrop_path\":\"/zAqBIeO71BFL7bAtP5TFzVjVamy.jpg\",\"genre_ids\":[10749,18],\"id\":1079091,\"original_language\":\"en\",\"original_title\":\"It Ends with Us\",\"overview\":\"When a woman's first love suddenly reenters her life, her relationship with a charming, but abusive neurosurgeon is upended, and she realizes she must learn to rely on her own strength to make an impossible choice for her future.\",\"popularity\":1085.011,\"poster_path\":\"/cSMdFWmajaX4oUMLx7HEDI84GkP.jpg\",\"release_date\":\"2024-08-07\",\"title\":\"It Ends with Us\",\"video\":false,\"vote_average\":7.02,\"vote_count\":689},{\"adult\":false,\"backdrop_path\":\"/gZWl93sf8AxavYpVT1Un6EF3oCj.jpg\",\"genre_ids\":[80,53,18],\"id\":475557,\"original_language\":\"en\",\"original_title\":\"Joker\",\"overview\":\"During the 1980s, a failed stand-up comedian is driven insane and turns to a life of crime and chaos in Gotham City while becoming an infamous psychopathic crime figure.\",\"popularity\":974.076,\"poster_path\":\"/udDclJoHjfjb8Ekgsd4FDteOkCU.jpg\",\"release_date\":\"2019-10-01\",\"title\":\"Joker\",\"video\":false,\"vote_average\":8.154,\"vote_count\":25323},{\"adult\":false,\"backdrop_path\":\"/1pbV8uC6EUYOYnPqWfrQFPdAj1O.jpg\",\"genre_ids\":[80,28,53],\"id\":1147710,\"original_language\":\"ko\",\"original_title\":\"하이재킹\",\"overview\":\"Pilots Tae-in and Gyu-sik are set to fly to Gimpo. Under the guidance of flight attendant Ok-soon, passengers are busy boarding. However, shortly after takeoff, a homemade bomb explodes, turning the cabin into chaos.\",\"popularity\":968.532,\"poster_path\":\"/68jNkFi61MQjrJEqj2up5wZ4w5R.jpg\",\"release_date\":\"2024-06-21\",\"title\":\"Hijack 1971\",\"video\":false,\"vote_average\":5.94,\"vote_count\":50},{\"adult\":false,\"backdrop_path\":\"/blqiNjJefmY10Wx6y2vgJJWljJj.jpg\",\"genre_ids\":[28,53],\"id\":949484,\"original_language\":\"en\",\"original_title\":\"Hounds of War\",\"overview\":\"After a mission goes wrong, only one of a group of mercenaries is left alive to avenge his fallen brothers.\",\"popularity\":734.631,\"poster_path\":\"/lRBT73EWsiQPuqK3YS3BnBW0Zwi.jpg\",\"release_date\":\"2024-08-29\",\"title\":\"Hounds of War\",\"video\":false,\"vote_average\":6.453,\"vote_count\":74},{\"adult\":false,\"backdrop_path\":\"/mKOBdgaEFguADkJhfFslY7TYxIh.jpg\",\"genre_ids\":[28,878,35],\"id\":365177,\"original_language\":\"en\",\"original_title\":\"Borderlands\",\"overview\":\"Returning to her home planet, an infamous bounty hunter forms an unexpected alliance with a team of unlikely heroes. Together, they battle monsters and dangerous bandits to protect a young girl who holds the key to unimaginable power.\",\"popularity\":723.922,\"poster_path\":\"/865DntZzOdX6rLMd405R0nFkLmL.jpg\",\"release_date\":\"2024-08-07\",\"title\":\"Borderlands\",\"video\":false,\"vote_average\":5.894,\"vote_count\":649},{\"adult\":false,\"backdrop_path\":\"/tAwfoDyKiYa4KQdUp3DTMrEs4En.jpg\",\"genre_ids\":[16,878,12,10751,28],\"id\":698687,\"original_language\":\"en\",\"original_title\":\"Transformers One\",\"overview\":\"The untold origin story of Optimus Prime and Megatron, better known as sworn enemies, but once were friends bonded like brothers who changed the fate of Cybertron forever.\",\"popularity\":704.262,\"poster_path\":\"/qbkAqmmEIZfrCO8ZQAuIuVMlWoV.jpg\",\"release_date\":\"2024-09-11\",\"title\":\"Transformers One\",\"video\":false,\"vote_average\":7.4,\"vote_count\":119},{\"adult\":false,\"backdrop_path\":\"/bGwBlxl9Ht2zljBHfNQD0YCEtrk.jpg\",\"genre_ids\":[27,53],\"id\":807339,\"original_language\":\"en\",\"original_title\":\"Apartment 7A\",\"overview\":\"A struggling young dancer finds herself drawn in by dark forces when a peculiar, well-connected older couple promise her a shot at fame.\",\"popularity\":633.345,\"poster_path\":\"/oyjEPno8omeDYVNqUZS2RiEpuRC.jpg\",\"release_date\":\"2024-09-20\",\"title\":\"Apartment 7A\",\"video\":false,\"vote_average\":5.899,\"vote_count\":84},{\"adult\":false,\"backdrop_path\":\"/jfC2xCBD8a5QJNd5yY3q23E8i7U.jpg\",\"genre_ids\":[28,80,18],\"id\":1186947,\"original_language\":\"pt\",\"original_title\":\"Bandida - A Número Um\",\"overview\":\"At the age of nine, Rebeca is sold by her grandmother to the bookseller who ran Rocinha. Disputed by bicheiros and drug dealers, the community is going through changes in power. Rebeca becomes the wife of the chief drug dealer and, with the death of her partner, his successor. The electrifying trajectory of crime, violence, drugs and love of a female drug kingpin in Rocinha, Rio de Janeiro in the 1980s.\",\"popularity\":588.225,\"poster_path\":\"/rGS8SzheANVQicNba0GCE6w1XHb.jpg\",\"release_date\":\"2024-06-20\",\"title\":\"Outlaw\",\"video\":false,\"vote_average\":6.021,\"vote_count\":70},{\"adult\":false,\"backdrop_path\":\"/igtm12Wy9EUlxFeyb4v8bRyuYSY.jpg\",\"genre_ids\":[28,80,18,53],\"id\":1337309,\"original_language\":\"th\",\"original_title\":\"Bangkok Breaking: ฝ่านรกเมืองเทวดา\",\"overview\":\"When a dedicated rescue worker inadvertently gets caught up in the kidnapping plot of a mogul's tween daughter, he must save her from the clutches of rival gangs hunting them down with unpredictable dangers around every corner.\",\"popularity\":574.462,\"poster_path\":\"/6VeDn4oIeUK4XwjWGWMb6qvMImQ.jpg\",\"release_date\":\"2024-09-26\",\"title\":\"Bangkok Breaking: Heaven and Hell\",\"video\":false,\"vote_average\":6.833,\"vote_count\":18},{\"adult\":false,\"backdrop_path\":\"/9SSEUrSqhljBMzRe4aBTh17rUaC.jpg\",\"genre_ids\":[27,878,28],\"id\":945961,\"original_language\":\"en\",\"original_title\":\"Alien: Romulus\",\"overview\":\"While scavenging the deep ends of a derelict space station, a group of young space colonizers come face to face with the most terrifying life form in the universe.\",\"popularity\":565.572,\"poster_path\":\"/b33nnKl1GSFbao4l3fZDDqsMx0F.jpg\",\"release_date\":\"2024-08-13\",\"title\":\"Alien: Romulus\",\"video\":false,\"vote_average\":7.049,\"vote_count\":1123},{\"adult\":false,\"backdrop_path\":\"/wSZbtiFIK1fkKZdSRtn2kz2Ttfd.jpg\",\"genre_ids\":[28,35,80],\"id\":1139817,\"original_language\":\"ko\",\"original_title\":\"무도실무관\",\"overview\":\"A talented martial artist who can't walk past a person in need unites with a probation officer to fight and prevent crime as a martial arts officer.\",\"popularity\":546.842,\"poster_path\":\"/rEaJSXAlNfdhRpDHiNcJsoUa9qE.jpg\",\"release_date\":\"2024-09-10\",\"title\":\"Officer Black Belt\",\"video\":false,\"vote_average\":7.858,\"vote_count\":169}],\"total_pages\":262,\"total_results\":5227}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.themoviedb.org/3/movie/now_playing'\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIxMWQyYzg2YjY4YWUwMWE1MWRmZDcxNzZmOTE0OWUwYyIsIm5iZiI6MTcyODI4MDE1OS44OTI5NTUsInN1YiI6IjY3MDM3NGE5N2NmZWE2ZjIwMjczZDk1NiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.QV7gqbDiBD8mGPGJ2an-zjqbps21R4ScRXvQWSTEwBM\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies data saved to 'movies.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "#create a dataset of the movies in theaters now. Include metadata fields you are interested in. \n",
    "#save this dataset as \"movies.csv\"\n",
    "\n",
    "url = 'https://api.themoviedb.org/3/movie/now_playing'\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIxMWQyYzg2YjY4YWUwMWE1MWRmZDcxNzZmOTE0OWUwYyIsIm5iZiI6MTcyODI4MDE1OS44OTI5NTUsInN1YiI6IjY3MDM3NGE5N2NmZWE2ZjIwMjczZDk1NiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.QV7gqbDiBD8mGPGJ2an-zjqbps21R4ScRXvQWSTEwBM\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    movie_list = []\n",
    "\n",
    "    for movie in data['results']:\n",
    "        movie_data = {\n",
    "            'title': movie['title'],\n",
    "            'release_date': movie['release_date'],\n",
    "            'vote_average': movie['vote_average'],\n",
    "            'vote_count': movie['vote_count'],\n",
    "            'popularity': movie['popularity'],\n",
    "            'original_language': movie['original_language'],\n",
    "            'overview': movie['overview'],\n",
    "            'poster_path': movie['poster_path']\n",
    "        }\n",
    "        movie_list.append(movie_data)\n",
    "\n",
    "    df = pd.DataFrame(movie_list)\n",
    "\n",
    "    df.to_csv('movies.csv', index=False)\n",
    "\n",
    "    print(\"Movies data saved to 'movies.csv' successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded poster for Speak No Evil\n",
      "Downloaded poster for Wolfs\n",
      "Downloaded poster for The Crow\n",
      "Downloaded poster for The Substance\n",
      "Downloaded poster for Joker: Folie à Deux\n",
      "Downloaded poster for Kill 'em All 2\n",
      "Downloaded poster for Project Silence\n",
      "Downloaded poster for The Wild Robot\n",
      "Downloaded poster for Beetlejuice Beetlejuice\n",
      "Downloaded poster for It Ends with Us\n"
     ]
    }
   ],
   "source": [
    "#download the movie posters for 10 of these movies and save them to this repository\n",
    "\n",
    "df = pd.read_csv('movies.csv')\n",
    "\n",
    "base_image_url = 'https://image.tmdb.org/t/p/w500'\n",
    "\n",
    "if not os.path.exists('posters'):\n",
    "    os.makedirs('posters')\n",
    "\n",
    "for i in range(10):\n",
    "    poster_path = df.loc[i, 'poster_path']\n",
    "    movie_title = df.loc[i, 'title']\n",
    "\n",
    "    full_poster_url = base_image_url + poster_path\n",
    "\n",
    "    response = requests.get(full_poster_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(f'./posters/{movie_title}_poster.jpg', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded poster for {movie_title}\")\n",
    "    else:\n",
    "        print(f\"Failed to download poster for {movie_title}. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
